{"type": "error", "data": "Error executing verb \"entity_extract\" in create_base_extracted_entities: [Errno 32] Broken pipe", "stack": "Traceback (most recent call last):\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_base.py\", line 39, in execute\n    result = await result\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/verbs/entities/extraction/entity_extract.py\", line 151, in run_strategy\n    result = await strategy_exec(\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/verbs/entities/extraction/strategies/graph_intelligence/run_graph_intelligence.py\", line 40, in run_gi\n    return await run_extract_entities(llm, docs, entity_types, reporter, args)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/verbs/entities/extraction/strategies/graph_intelligence/run_graph_intelligence.py\", line 87, in run_extract_entities\n    results = await extractor(\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 146, in _process_document\n    response = await self._llm(\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/openai/_base_client.py\", line 1558, in _request\n    response = await self._client.send(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_client.py\", line 1661, in send\n    response = await self._send_handling_auth(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n    response = await self._send_handling_redirects(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n    response = await self._send_single_request(request)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n    response = await transport.handle_async_request(request)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n    raise exc from None\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n    response = await connection.handle_async_request(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n    return await self._connection.handle_async_request(request)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n    raise exc\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n    data = await self._network_stream.read(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n    return await self._stream.receive(max_bytes=max_bytes)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 1142, in receive\n    await self._protocol.read_event.wait()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/asyncio/locks.py\", line 214, in wait\n    await fut\nasyncio.exceptions.CancelledError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 415, in _execute_verb\n    result = await result\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/verbs/entities/extraction/entity_extract.py\", line 161, in entity_extract\n    results = await derive_from_rows(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows.py\", line 33, in derive_from_rows\n    return await derive_from_rows_asyncio_threads(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py\", line 40, in derive_from_rows_asyncio_threads\n    return await derive_from_rows_base(input, transform, callbacks, gather)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_base.py\", line 49, in derive_from_rows_base\n    result = await gather(execute)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py\", line 38, in gather\n    return await asyncio.gather(*[execute_task(task) for task in tasks])\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py\", line 36, in execute_task\n    return await thread\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_base.py\", line 47, in execute\n    tick(1)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/progress/progress_ticker.py\", line 21, in __call__\n    self._callback(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/verb_callbacks/delegating_verb_callbacks.py\", line 22, in progress\n    self._workflow_callbacks.on_step_progress(self._node, progress)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/workflow_callbacks/workflow_callbacks_manager.py\", line 51, in on_step_progress\n    callback.on_step_progress(node, progress)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/workflow_callbacks/workflow_callbacks_manager.py\", line 51, in on_step_progress\n    callback.on_step_progress(node, progress)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/reporting/progress_workflow_callbacks.py\", line 54, in on_step_progress\n    self._latest(progress)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/progress/rich.py\", line 165, in __call__\n    self.refresh()\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/progress/rich.py\", line 111, in refresh\n    self.force_refresh()\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/progress/rich.py\", line 115, in force_refresh\n    self.live.refresh()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/rich/live.py\", line 246, in refresh\n    with self.console:\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/rich/console.py\", line 865, in __exit__\n    self._exit_buffer()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/rich/console.py\", line 823, in _exit_buffer\n    self._check_buffer()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/rich/console.py\", line 2065, in _check_buffer\n    self.file.flush()\nBrokenPipeError: [Errno 32] Broken pipe\n", "source": "[Errno 32] Broken pipe", "details": null}
{"type": "error", "data": "Error running pipeline!", "stack": "Traceback (most recent call last):\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_base.py\", line 39, in execute\n    result = await result\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/verbs/entities/extraction/entity_extract.py\", line 151, in run_strategy\n    result = await strategy_exec(\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/verbs/entities/extraction/strategies/graph_intelligence/run_graph_intelligence.py\", line 40, in run_gi\n    return await run_extract_entities(llm, docs, entity_types, reporter, args)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/verbs/entities/extraction/strategies/graph_intelligence/run_graph_intelligence.py\", line 87, in run_extract_entities\n    results = await extractor(\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 118, in __call__\n    result = await self._process_document(text, prompt_variables)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/graph/extractors/graph/graph_extractor.py\", line 146, in _process_document\n    response = await self._llm(\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/openai/json_parsing_llm.py\", line 34, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/openai/openai_token_replacing_llm.py\", line 37, in __call__\n    return await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/openai/openai_history_tracking_llm.py\", line 33, in __call__\n    output = await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/caching_llm.py\", line 104, in __call__\n    result = await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/rate_limiting_llm.py\", line 177, in __call__\n    result, start = await execute_with_retry()\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/rate_limiting_llm.py\", line 159, in execute_with_retry\n    async for attempt in retryer:\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 166, in __anext__\n    do = await self.iter(retry_state=self._retry_state)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n    result = await action(retry_state)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/tenacity/_utils.py\", line 99, in inner\n    return call(*args, **kwargs)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/tenacity/__init__.py\", line 398, in <lambda>\n    self._add_action_func(lambda rs: rs.outcome.result())\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n    return self.__get_result()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n    raise self._exception\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/rate_limiting_llm.py\", line 165, in execute_with_retry\n    return await do_attempt(), start\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/rate_limiting_llm.py\", line 147, in do_attempt\n    return await self._delegate(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/base_llm.py\", line 49, in __call__\n    return await self._invoke(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/base/base_llm.py\", line 53, in _invoke\n    output = await self._execute_llm(input, **kwargs)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/llm/openai/openai_chat_llm.py\", line 55, in _execute_llm\n    completion = await self.client.chat.completions.create(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 1289, in create\n    return await self._post(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/openai/_base_client.py\", line 1826, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/openai/_base_client.py\", line 1519, in request\n    return await self._request(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/openai/_base_client.py\", line 1558, in _request\n    response = await self._client.send(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_client.py\", line 1661, in send\n    response = await self._send_handling_auth(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_client.py\", line 1689, in _send_handling_auth\n    response = await self._send_handling_redirects(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_client.py\", line 1726, in _send_handling_redirects\n    response = await self._send_single_request(request)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_client.py\", line 1763, in _send_single_request\n    response = await transport.handle_async_request(request)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpx/_transports/default.py\", line 373, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 216, in handle_async_request\n    raise exc from None\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/connection_pool.py\", line 196, in handle_async_request\n    response = await connection.handle_async_request(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n    return await self._connection.handle_async_request(request)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 143, in handle_async_request\n    raise exc\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 113, in handle_async_request\n    ) = await self._receive_response_headers(**kwargs)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 186, in _receive_response_headers\n    event = await self._receive_event(timeout=timeout)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_async/http11.py\", line 224, in _receive_event\n    data = await self._network_stream.read(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/httpcore/_backends/anyio.py\", line 35, in read\n    return await self._stream.receive(max_bytes=max_bytes)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 1142, in receive\n    await self._protocol.read_event.wait()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/asyncio/locks.py\", line 214, in wait\n    await fut\nasyncio.exceptions.CancelledError\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/run.py\", line 323, in run_pipeline\n    result = await workflow.run(context, callbacks)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 369, in run\n    timing = await self._execute_verb(node, context, callbacks)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/workflow.py\", line 415, in _execute_verb\n    result = await result\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/verbs/entities/extraction/entity_extract.py\", line 161, in entity_extract\n    results = await derive_from_rows(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows.py\", line 33, in derive_from_rows\n    return await derive_from_rows_asyncio_threads(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py\", line 40, in derive_from_rows_asyncio_threads\n    return await derive_from_rows_base(input, transform, callbacks, gather)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_base.py\", line 49, in derive_from_rows_base\n    result = await gather(execute)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py\", line 38, in gather\n    return await asyncio.gather(*[execute_task(task) for task in tasks])\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_asyncio_threads.py\", line 36, in execute_task\n    return await thread\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/execution/derive_from_rows_base.py\", line 47, in execute\n    tick(1)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/progress/progress_ticker.py\", line 21, in __call__\n    self._callback(\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/verb_callbacks/delegating_verb_callbacks.py\", line 22, in progress\n    self._workflow_callbacks.on_step_progress(self._node, progress)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/workflow_callbacks/workflow_callbacks_manager.py\", line 51, in on_step_progress\n    callback.on_step_progress(node, progress)\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/datashaper/workflow/workflow_callbacks/workflow_callbacks_manager.py\", line 51, in on_step_progress\n    callback.on_step_progress(node, progress)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/reporting/progress_workflow_callbacks.py\", line 54, in on_step_progress\n    self._latest(progress)\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/progress/rich.py\", line 165, in __call__\n    self.refresh()\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/progress/rich.py\", line 111, in refresh\n    self.force_refresh()\n  File \"/Users/anima/GraphRAG-Ollama-UI-main/graphrag/index/progress/rich.py\", line 115, in force_refresh\n    self.live.refresh()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/rich/live.py\", line 246, in refresh\n    with self.console:\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/rich/console.py\", line 865, in __exit__\n    self._exit_buffer()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/rich/console.py\", line 823, in _exit_buffer\n    self._check_buffer()\n  File \"/Users/anima/anaconda3/envs/graphrag/lib/python3.10/site-packages/rich/console.py\", line 2065, in _check_buffer\n    self.file.flush()\nBrokenPipeError: [Errno 32] Broken pipe\n", "source": "[Errno 32] Broken pipe", "details": null}
